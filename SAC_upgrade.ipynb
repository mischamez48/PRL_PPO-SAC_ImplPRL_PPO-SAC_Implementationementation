{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import gym\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (16, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Sequential(nn.Linear(in_features, out_features), nn.ReLU())\n",
    "    def forward(self, x):\n",
    "        x = self.linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, s_dim, a_dim, hidden_dim=256, num_hidden_layers=2):\n",
    "        super(Actor, self).__init__()\n",
    "\n",
    "        self.s_dim = s_dim\n",
    "        self.a_dim = a_dim\n",
    "\n",
    "        layers = [LinearLayer(s_dim, hidden_dim)]\n",
    "        for _ in range(num_hidden_layers):\n",
    "            layers.append(LinearLayer(hidden_dim, hidden_dim))\n",
    "        layers.append(nn.Linear(hidden_dim, a_dim))\n",
    "\n",
    "        self.f = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, state):\n",
    "        if not isinstance(state, torch.Tensor):\n",
    "            state = torch.tensor(state, dtype=torch.float32)\n",
    "        out = self.f(state)\n",
    "        #out = torch.tanh(out)\n",
    "        out= F.softmax(out+1e-10, dim=-1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QDNN(nn.Module):\n",
    "    def __init__(self, s_dim, a_dim, hidden_dim=256, num_hidden_layers=2):\n",
    "        super(QDNN, self).__init__()\n",
    "\n",
    "        self.s_dim = s_dim\n",
    "        self.a_dim = a_dim\n",
    "\n",
    "        layers = [LinearLayer(s_dim + a_dim, hidden_dim)]\n",
    "        for _ in range(num_hidden_layers):\n",
    "            layers.append(LinearLayer(hidden_dim, hidden_dim))\n",
    "        layers.append(nn.Linear(hidden_dim, 1))\n",
    "\n",
    "        self.f = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], dim=1)\n",
    "        out = self.f(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, s_dim, a_dim, hidden_dim=256, num_hidden_layers=2):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        self.s_dim = s_dim\n",
    "        self.a_dim = a_dim\n",
    "\n",
    "        # Two DNNs to mitigate positive bias\n",
    "        self.Q1 = QDNN(s_dim, a_dim, hidden_dim, num_hidden_layers)\n",
    "        self.Q2 = QDNN(s_dim, a_dim, hidden_dim, num_hidden_layers)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        q1 = self.Q1(state, action)\n",
    "        q2 = self.Q2(state, action)\n",
    "        return q1, q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAC():\n",
    "    def __init__(self, s_dim, a_dim, hidden_dim_actor=256, hidden_dim_critic=256, \n",
    "                 num_layer_actor=2, num_layer_critic=2, lr_act=3e-4, lr_crit=3e-4, \n",
    "                 gamma=0.99, tau=0.005, alpha=0.2, lambd=0.005, target_upd_inter=1, \n",
    "                 buffer_capacity=1000, batch_size=32, grad_steps = 1, device=\"cpu\"):\n",
    "        \n",
    "        self.s_dim = s_dim\n",
    "        self.a_dim = a_dim\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer = deque(maxlen=buffer_capacity)\n",
    "        self.grad_steps = grad_steps\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.lambd = lambd\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.target_upd_inter = target_upd_inter\n",
    "\n",
    "        self.actor = Actor(s_dim, a_dim, hidden_dim_actor, num_hidden_layers=num_layer_actor).to(device)\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=lr_act)\n",
    "\n",
    "        self.critic = Critic(s_dim, a_dim, hidden_dim_critic, num_hidden_layers=num_layer_critic).to(device)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=lr_crit)\n",
    "\n",
    "        # Stabilize training\n",
    "        self.critic_target = copy.deepcopy(self.critic).to(device)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        self.actor.eval()\n",
    "        if not isinstance(state, torch.Tensor):\n",
    "            state = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            action_probs = self.actor(state.to(self.device))\n",
    "            dist = Categorical(action_probs)\n",
    "            action = dist.sample()\n",
    "        return action.item(), action_probs.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    def train(self, update_interval):\n",
    "        if len(self.buffer) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        for i in range(self.grad_steps):\n",
    "            batch = random.sample(self.buffer, self.batch_size)\n",
    "            states, actions, rewards, next_states, dones = zip(*batch)\n",
    "            states = torch.tensor(states, dtype=torch.float32).to(self.device)\n",
    "            actions = torch.tensor(actions, dtype=torch.float32).squeeze().to(self.device)\n",
    "            rewards = torch.tensor(rewards, dtype=torch.float32).unsqueeze(1).to(self.device)\n",
    "            next_states = torch.tensor(next_states, dtype=torch.float32).to(self.device)\n",
    "            dones = torch.tensor(dones, dtype=torch.float32).to(self.device)\n",
    "            #print(dones)\n",
    "            \n",
    "            # Critic train\n",
    "            self.critic.train()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                probs = self.actor(next_states)\n",
    "                dist = Categorical(probs)\n",
    "                sampled_actions = dist.sample()\n",
    "                next_actions_log_probs = dist.log_prob(sampled_actions).unsqueeze(1)\n",
    "                q1_next, q2_next = self.critic_target(next_states, probs)\n",
    "                min_q_next = torch.min(q1_next, q2_next)\n",
    "                #print((torch.ones_like(dones)-dones).shape)\n",
    "                target_q_value = rewards + self.gamma *(torch.ones_like(dones)-dones).unsqueeze(1)*(min_q_next - self.alpha * next_actions_log_probs)#.sum(-1, keepdim=True))\n",
    "                \n",
    "            q1, q2 = self.critic(states, actions)\n",
    "            \n",
    "            critic_loss = F.mse_loss(q1, target_q_value.detach()) + F.mse_loss(q2, target_q_value.detach())\n",
    "\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            self.critic_optimizer.step()\n",
    "\n",
    "            # Actor train\n",
    "            self.actor.train()\n",
    "\n",
    "            probs = self.actor(states)\n",
    "            dist = Categorical(probs)\n",
    "            sampled_actions = dist.sample()\n",
    "            log_probs = dist.log_prob(sampled_actions)#.sum(-1, keepdim=True)\n",
    "            q1_actor, q2_actor = self.critic(states, probs)\n",
    "            min_q_actor = torch.min(q1_actor, q2_actor)\n",
    "            \n",
    "            actor_loss = (self.alpha * log_probs.unsqueeze(1) - min_q_actor).mean()\n",
    "\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "\n",
    "            # Soft update of target networks\n",
    "            if update_interval % self.target_upd_inter == 0:\n",
    "                for target_parameters, parameters in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
    "                    target_parameters.data.copy_(self.tau * parameters.data + (1.0 - self.tau) * target_parameters.data)\n",
    "\n",
    "        #print(critic_loss.item(), actor_loss.item())\n",
    "        return critic_loss.item(), actor_loss.item()\n",
    "\n",
    "    def add_elements_to_buffer(self, state, probs, reward, next_state, done):\n",
    "        self.buffer.append((state, probs, reward, next_state, done))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0 score 17.0 avg score 17.0\n",
      "episode 1 score 15.0 avg score 16.0\n",
      "episode 2 score 11.0 avg score 14.3\n",
      "episode 3 score 15.0 avg score 14.5\n",
      "episode 4 score 15.0 avg score 14.6\n",
      "episode 5 score 11.0 avg score 14.0\n",
      "episode 6 score 12.0 avg score 13.7\n",
      "episode 7 score 13.0 avg score 13.6\n",
      "episode 8 score 9.0 avg score 13.1\n",
      "episode 9 score 11.0 avg score 12.9\n",
      "episode 10 score 10.0 avg score 12.6\n",
      "episode 11 score 10.0 avg score 12.4\n",
      "episode 12 score 9.0 avg score 12.2\n",
      "episode 13 score 9.0 avg score 11.9\n",
      "episode 14 score 8.0 avg score 11.7\n",
      "episode 15 score 11.0 avg score 11.6\n",
      "episode 16 score 40.0 avg score 13.3\n",
      "episode 17 score 34.0 avg score 14.4\n",
      "episode 18 score 36.0 avg score 15.6\n",
      "episode 19 score 110.0 avg score 20.3\n",
      "episode 20 score 58.0 avg score 22.1\n",
      "episode 21 score 33.0 avg score 22.6\n",
      "episode 22 score 31.0 avg score 23.0\n",
      "episode 23 score 47.0 avg score 24.0\n",
      "episode 24 score 125.0 avg score 28.0\n",
      "episode 25 score 200.0 avg score 34.6\n",
      "episode 26 score 195.0 avg score 40.6\n",
      "episode 27 score 200.0 avg score 46.2\n",
      "episode 28 score 196.0 avg score 51.4\n",
      "episode 29 score 200.0 avg score 56.4\n",
      "episode 30 score 157.0 avg score 59.6\n",
      "episode 31 score 200.0 avg score 64.0\n",
      "episode 32 score 200.0 avg score 68.1\n",
      "episode 33 score 200.0 avg score 72.0\n",
      "episode 34 score 200.0 avg score 75.7\n",
      "episode 35 score 200.0 avg score 79.1\n",
      "episode 36 score 200.0 avg score 82.4\n",
      "episode 37 score 200.0 avg score 85.5\n",
      "episode 38 score 200.0 avg score 88.4\n",
      "episode 39 score 200.0 avg score 91.2\n",
      "episode 40 score 200.0 avg score 93.9\n",
      "episode 41 score 200.0 avg score 96.4\n",
      "episode 42 score 200.0 avg score 98.8\n",
      "episode 43 score 200.0 avg score 101.1\n",
      "episode 44 score 200.0 avg score 103.3\n",
      "episode 45 score 200.0 avg score 105.4\n",
      "episode 46 score 200.0 avg score 107.4\n",
      "episode 47 score 200.0 avg score 109.3\n",
      "episode 48 score 200.0 avg score 111.2\n",
      "episode 49 score 200.0 avg score 113.0\n",
      "episode 50 score 200.0 avg score 114.7\n",
      "episode 51 score 200.0 avg score 116.3\n",
      "episode 52 score 200.0 avg score 117.9\n",
      "episode 53 score 200.0 avg score 119.4\n",
      "episode 54 score 200.0 avg score 120.9\n",
      "episode 55 score 200.0 avg score 122.3\n",
      "episode 56 score 200.0 avg score 123.6\n",
      "episode 57 score 200.0 avg score 125.0\n",
      "episode 58 score 200.0 avg score 126.2\n",
      "episode 59 score 200.0 avg score 127.5\n",
      "episode 60 score 200.0 avg score 128.7\n",
      "episode 61 score 200.0 avg score 129.8\n",
      "episode 62 score 200.0 avg score 130.9\n",
      "episode 63 score 200.0 avg score 132.0\n",
      "episode 64 score 200.0 avg score 133.0\n",
      "episode 65 score 200.0 avg score 134.1\n",
      "episode 66 score 200.0 avg score 135.0\n",
      "episode 67 score 200.0 avg score 136.0\n",
      "episode 68 score 200.0 avg score 136.9\n",
      "episode 69 score 200.0 avg score 137.8\n",
      "episode 70 score 200.0 avg score 138.7\n",
      "episode 71 score 200.0 avg score 139.6\n",
      "episode 72 score 200.0 avg score 140.4\n",
      "episode 73 score 200.0 avg score 141.2\n",
      "episode 74 score 200.0 avg score 142.0\n",
      "episode 75 score 177.0 avg score 142.4\n",
      "episode 76 score 200.0 avg score 143.2\n",
      "episode 77 score 200.0 avg score 143.9\n",
      "episode 78 score 200.0 avg score 144.6\n",
      "episode 79 score 200.0 avg score 145.3\n",
      "episode 80 score 200.0 avg score 146.0\n",
      "episode 81 score 200.0 avg score 146.6\n",
      "episode 82 score 200.0 avg score 147.3\n",
      "episode 83 score 200.0 avg score 147.9\n",
      "episode 84 score 200.0 avg score 148.5\n",
      "episode 85 score 200.0 avg score 149.1\n",
      "episode 86 score 200.0 avg score 149.7\n",
      "episode 87 score 200.0 avg score 150.3\n",
      "episode 88 score 200.0 avg score 150.8\n",
      "episode 89 score 200.0 avg score 151.4\n",
      "episode 90 score 200.0 avg score 151.9\n",
      "episode 91 score 200.0 avg score 152.4\n",
      "episode 92 score 200.0 avg score 153.0\n",
      "episode 93 score 200.0 avg score 153.5\n",
      "episode 94 score 200.0 avg score 153.9\n",
      "episode 95 score 200.0 avg score 154.4\n",
      "episode 96 score 200.0 avg score 154.9\n",
      "episode 97 score 200.0 avg score 155.4\n",
      "episode 98 score 200.0 avg score 155.8\n",
      "episode 99 score 200.0 avg score 156.2\n",
      "episode 100 score 200.0 avg score 158.1\n",
      "episode 101 score 200.0 avg score 159.9\n",
      "episode 102 score 200.0 avg score 161.8\n",
      "episode 103 score 200.0 avg score 163.7\n",
      "episode 104 score 200.0 avg score 165.5\n",
      "episode 105 score 200.0 avg score 167.4\n",
      "episode 106 score 200.0 avg score 169.3\n",
      "episode 107 score 200.0 avg score 171.2\n",
      "episode 108 score 200.0 avg score 173.1\n",
      "episode 109 score 200.0 avg score 175.0\n",
      "episode 110 score 200.0 avg score 176.9\n",
      "episode 111 score 200.0 avg score 178.8\n",
      "episode 112 score 200.0 avg score 180.7\n",
      "episode 113 score 200.0 avg score 182.6\n",
      "episode 114 score 200.0 avg score 184.5\n",
      "episode 115 score 200.0 avg score 186.4\n",
      "episode 116 score 200.0 avg score 188.0\n",
      "episode 117 score 200.0 avg score 189.7\n",
      "episode 118 score 200.0 avg score 191.3\n",
      "episode 119 score 200.0 avg score 192.2\n",
      "episode 120 score 182.0 avg score 193.4\n",
      "episode 121 score 200.0 avg score 195.1\n",
      "episode 122 score 200.0 avg score 196.8\n",
      "episode 123 score 200.0 avg score 198.3\n",
      "episode 124 score 200.0 avg score 199.1\n",
      "episode 125 score 200.0 avg score 199.1\n",
      "episode 126 score 200.0 avg score 199.1\n",
      "episode 127 score 200.0 avg score 199.1\n",
      "episode 128 score 200.0 avg score 199.2\n",
      "episode 129 score 200.0 avg score 199.2\n",
      "episode 130 score 200.0 avg score 199.6\n",
      "episode 131 score 200.0 avg score 199.6\n",
      "episode 132 score 200.0 avg score 199.6\n",
      "episode 133 score 200.0 avg score 199.6\n",
      "episode 134 score 200.0 avg score 199.6\n",
      "episode 135 score 200.0 avg score 199.6\n",
      "episode 136 score 200.0 avg score 199.6\n",
      "episode 137 score 200.0 avg score 199.6\n",
      "episode 138 score 200.0 avg score 199.6\n",
      "episode 139 score 200.0 avg score 199.6\n",
      "episode 140 score 200.0 avg score 199.6\n",
      "episode 141 score 200.0 avg score 199.6\n",
      "episode 142 score 200.0 avg score 199.6\n",
      "episode 143 score 200.0 avg score 199.6\n",
      "episode 144 score 200.0 avg score 199.6\n",
      "episode 145 score 200.0 avg score 199.6\n",
      "episode 146 score 200.0 avg score 199.6\n",
      "episode 147 score 200.0 avg score 199.6\n",
      "episode 148 score 200.0 avg score 199.6\n",
      "episode 149 score 200.0 avg score 199.6\n",
      "episode 150 score 200.0 avg score 199.6\n",
      "episode 151 score 200.0 avg score 199.6\n",
      "episode 152 score 200.0 avg score 199.6\n",
      "episode 153 score 195.0 avg score 199.5\n",
      "episode 154 score 200.0 avg score 199.5\n",
      "episode 155 score 200.0 avg score 199.5\n",
      "episode 156 score 200.0 avg score 199.5\n",
      "episode 157 score 200.0 avg score 199.5\n",
      "episode 158 score 200.0 avg score 199.5\n",
      "episode 159 score 200.0 avg score 199.5\n",
      "episode 160 score 115.0 avg score 198.7\n",
      "episode 161 score 200.0 avg score 198.7\n",
      "episode 162 score 200.0 avg score 198.7\n",
      "episode 163 score 200.0 avg score 198.7\n",
      "episode 164 score 200.0 avg score 198.7\n",
      "episode 165 score 200.0 avg score 198.7\n",
      "episode 166 score 200.0 avg score 198.7\n",
      "episode 167 score 200.0 avg score 198.7\n",
      "episode 168 score 162.0 avg score 198.3\n",
      "episode 169 score 200.0 avg score 198.3\n",
      "episode 170 score 200.0 avg score 198.3\n",
      "episode 171 score 200.0 avg score 198.3\n",
      "episode 172 score 200.0 avg score 198.3\n",
      "episode 173 score 200.0 avg score 198.3\n",
      "episode 174 score 200.0 avg score 198.3\n",
      "episode 175 score 200.0 avg score 198.5\n",
      "episode 176 score 200.0 avg score 198.5\n",
      "episode 177 score 200.0 avg score 198.5\n",
      "episode 178 score 200.0 avg score 198.5\n",
      "episode 179 score 200.0 avg score 198.5\n",
      "episode 180 score 200.0 avg score 198.5\n",
      "episode 181 score 200.0 avg score 198.5\n",
      "episode 182 score 200.0 avg score 198.5\n",
      "episode 183 score 200.0 avg score 198.5\n",
      "episode 184 score 200.0 avg score 198.5\n",
      "episode 185 score 200.0 avg score 198.5\n",
      "episode 186 score 200.0 avg score 198.5\n",
      "episode 187 score 200.0 avg score 198.5\n",
      "episode 188 score 200.0 avg score 198.5\n",
      "episode 189 score 200.0 avg score 198.5\n",
      "episode 190 score 200.0 avg score 198.5\n",
      "episode 191 score 200.0 avg score 198.5\n",
      "episode 192 score 200.0 avg score 198.5\n",
      "episode 193 score 200.0 avg score 198.5\n",
      "episode 194 score 200.0 avg score 198.5\n",
      "episode 195 score 200.0 avg score 198.5\n",
      "episode 196 score 200.0 avg score 198.5\n",
      "episode 197 score 200.0 avg score 198.5\n",
      "episode 198 score 200.0 avg score 198.5\n",
      "episode 199 score 200.0 avg score 198.5\n",
      "episode 200 score 200.0 avg score 198.5\n",
      "episode 201 score 200.0 avg score 198.5\n",
      "episode 202 score 200.0 avg score 198.5\n",
      "episode 203 score 200.0 avg score 198.5\n",
      "episode 204 score 200.0 avg score 198.5\n",
      "episode 205 score 200.0 avg score 198.5\n",
      "episode 206 score 200.0 avg score 198.5\n",
      "episode 207 score 200.0 avg score 198.5\n",
      "episode 208 score 200.0 avg score 198.5\n",
      "episode 209 score 200.0 avg score 198.5\n",
      "episode 210 score 200.0 avg score 198.5\n",
      "episode 211 score 200.0 avg score 198.5\n",
      "episode 212 score 200.0 avg score 198.5\n",
      "episode 213 score 200.0 avg score 198.5\n",
      "episode 214 score 200.0 avg score 198.5\n",
      "episode 215 score 200.0 avg score 198.5\n",
      "episode 216 score 200.0 avg score 198.5\n",
      "episode 217 score 200.0 avg score 198.5\n",
      "episode 218 score 200.0 avg score 198.5\n",
      "episode 219 score 200.0 avg score 198.5\n",
      "episode 220 score 200.0 avg score 198.7\n",
      "episode 221 score 200.0 avg score 198.7\n",
      "episode 222 score 200.0 avg score 198.7\n",
      "episode 223 score 200.0 avg score 198.7\n",
      "episode 224 score 200.0 avg score 198.7\n",
      "episode 225 score 200.0 avg score 198.7\n",
      "episode 226 score 200.0 avg score 198.7\n",
      "episode 227 score 200.0 avg score 198.7\n",
      "episode 228 score 200.0 avg score 198.7\n",
      "episode 229 score 200.0 avg score 198.7\n",
      "episode 230 score 200.0 avg score 198.7\n",
      "episode 231 score 200.0 avg score 198.7\n",
      "episode 232 score 200.0 avg score 198.7\n",
      "episode 233 score 200.0 avg score 198.7\n",
      "episode 234 score 200.0 avg score 198.7\n",
      "episode 235 score 200.0 avg score 198.7\n",
      "episode 236 score 200.0 avg score 198.7\n",
      "episode 237 score 200.0 avg score 198.7\n",
      "episode 238 score 200.0 avg score 198.7\n",
      "episode 239 score 200.0 avg score 198.7\n",
      "episode 240 score 200.0 avg score 198.7\n",
      "episode 241 score 200.0 avg score 198.7\n",
      "episode 242 score 200.0 avg score 198.7\n",
      "episode 243 score 200.0 avg score 198.7\n",
      "episode 244 score 200.0 avg score 198.7\n",
      "episode 245 score 200.0 avg score 198.7\n",
      "episode 246 score 200.0 avg score 198.7\n",
      "episode 247 score 200.0 avg score 198.7\n",
      "episode 248 score 200.0 avg score 198.7\n",
      "episode 249 score 200.0 avg score 198.7\n",
      "episode 250 score 200.0 avg score 198.7\n",
      "episode 251 score 200.0 avg score 198.7\n",
      "episode 252 score 200.0 avg score 198.7\n",
      "episode 253 score 200.0 avg score 198.8\n",
      "episode 254 score 200.0 avg score 198.8\n",
      "episode 255 score 200.0 avg score 198.8\n",
      "episode 256 score 200.0 avg score 198.8\n",
      "episode 257 score 200.0 avg score 198.8\n",
      "episode 258 score 200.0 avg score 198.8\n",
      "episode 259 score 200.0 avg score 198.8\n",
      "episode 260 score 200.0 avg score 199.6\n",
      "episode 261 score 200.0 avg score 199.6\n",
      "episode 262 score 200.0 avg score 199.6\n",
      "episode 263 score 200.0 avg score 199.6\n",
      "episode 264 score 200.0 avg score 199.6\n",
      "episode 265 score 183.0 avg score 199.4\n",
      "episode 266 score 200.0 avg score 199.4\n",
      "episode 267 score 200.0 avg score 199.4\n",
      "episode 268 score 200.0 avg score 199.8\n",
      "episode 269 score 200.0 avg score 199.8\n",
      "episode 270 score 200.0 avg score 199.8\n",
      "episode 271 score 200.0 avg score 199.8\n",
      "episode 272 score 200.0 avg score 199.8\n",
      "episode 273 score 200.0 avg score 199.8\n",
      "episode 274 score 200.0 avg score 199.8\n",
      "episode 275 score 200.0 avg score 199.8\n",
      "episode 276 score 200.0 avg score 199.8\n",
      "episode 277 score 200.0 avg score 199.8\n",
      "episode 278 score 200.0 avg score 199.8\n",
      "episode 279 score 200.0 avg score 199.8\n",
      "episode 280 score 200.0 avg score 199.8\n",
      "episode 281 score 200.0 avg score 199.8\n",
      "episode 282 score 200.0 avg score 199.8\n",
      "episode 283 score 200.0 avg score 199.8\n",
      "episode 284 score 200.0 avg score 199.8\n",
      "episode 285 score 200.0 avg score 199.8\n",
      "episode 286 score 200.0 avg score 199.8\n",
      "episode 287 score 200.0 avg score 199.8\n",
      "episode 288 score 200.0 avg score 199.8\n",
      "episode 289 score 200.0 avg score 199.8\n",
      "episode 290 score 200.0 avg score 199.8\n",
      "episode 291 score 200.0 avg score 199.8\n",
      "episode 292 score 200.0 avg score 199.8\n",
      "episode 293 score 200.0 avg score 199.8\n",
      "episode 294 score 200.0 avg score 199.8\n",
      "episode 295 score 186.0 avg score 199.7\n",
      "episode 296 score 200.0 avg score 199.7\n",
      "episode 297 score 200.0 avg score 199.7\n",
      "episode 298 score 200.0 avg score 199.7\n",
      "episode 299 score 200.0 avg score 199.7\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (201,) and (200,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode\u001b[39m\u001b[38;5;124m'\u001b[39m, i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore \u001b[39m\u001b[38;5;132;01m%.1f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m score, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg score \u001b[39m\u001b[38;5;132;01m%.1f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m avg_score)\n\u001b[0;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(score_history))]\n\u001b[1;32m---> 39\u001b[0m \u001b[43mplot_learning_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigure_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m, in \u001b[0;36mplot_learning_curve\u001b[1;34m(x, scores, figure_file)\u001b[0m\n\u001b[0;32m      3\u001b[0m running_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(scores)\n\u001b[0;32m      4\u001b[0m running_avg \u001b[38;5;241m=\u001b[39m (running_sum[window_size:] \u001b[38;5;241m-\u001b[39m running_sum[:\u001b[38;5;241m-\u001b[39mwindow_size]) \u001b[38;5;241m/\u001b[39m window_size\n\u001b[1;32m----> 6\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_avg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning average of previous 100 scores\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpisode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\guill\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\pyplot.py:3590\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3582\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3584\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3588\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3594\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3595\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3596\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guill\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1724\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1724\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1725\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1726\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\guill\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guill\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (201,) and (200,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.seed(0)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "n_games = 300\n",
    "agent = SAC(state_dim, action_dim, buffer_capacity=int(1e6), hidden_dim_actor = 128, hidden_dim_critic=128, \n",
    "            num_layer_actor=2, num_layer_critic=2, lr_act=6e-4, lr_crit=6e-4, alpha=0.2, tau=0.05, batch_size=20, \n",
    "            grad_steps=2, device=device)\n",
    "\n",
    "figure_file = 'plots/cartpoleV0.png'\n",
    "\n",
    "best_score = env.reward_range[0]\n",
    "score_history = []\n",
    "\n",
    "learn_iters = 0\n",
    "avg_score = 0\n",
    "n_steps = 0\n",
    "training_interval=1\n",
    "update_interval = 1\n",
    "\n",
    "\n",
    "for i in range(n_games):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        action, probs = agent.choose_action(observation)\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        agent.add_elements_to_buffer(observation, probs, reward, observation_, done)\n",
    "        observation = observation_\n",
    "        update_interval += 1\n",
    "        n_steps += 1\n",
    "        if n_steps % training_interval == 0:\n",
    "            agent.train(update_interval)\n",
    "\n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-100:])\n",
    "    print('episode', i, 'score %.1f' % score, 'avg score %.1f' % avg_score)\n",
    "\n",
    "x = [i+1 for i in range(len(score_history))]\n",
    "plot_learning_curve(x[:-1], score_history, figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m ax \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m111\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Plot the scores with specified colors and labels\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m ax\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mscores\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), scores, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Set the labels with a larger font size\u001b[39;00m\n\u001b[0;32m     11\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal reward (= time balanced)\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Plot the learning progress\n",
    "\n",
    "# Create the plot\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Plot the scores with specified colors and labels\n",
    "ax.plot(np.arange(1, len(scores) + 1), scores, color='green', label='SAC')\n",
    "\n",
    "# Set the labels with a larger font size\n",
    "ax.set_ylabel('Total reward (= time balanced)', fontsize=20)\n",
    "ax.set_xlabel('Episode #', fontsize=20)\n",
    "\n",
    "# Set the tick labels to a larger font size\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "# Add a legend with a specified font size\n",
    "ax.legend(fontsize=20)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
